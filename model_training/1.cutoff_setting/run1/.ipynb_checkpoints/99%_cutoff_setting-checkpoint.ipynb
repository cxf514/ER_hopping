{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author=cxf\n",
    "# date=2020-8-8\n",
    "\"\"\"\n",
    "    file for setting the optimal cutoff for each sample according to the criterion\n",
    "    1.after filtering error rate less than 0.002 (1/5 of 0.01)\n",
    "    2.after filtering the number of genotyped sites is the largest and record the number\n",
    "    (check among points where the error rate less than 0.002)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "i = '../../0.prepare_processing/run1/error.txt'\n",
    "name = i.split('.')[0]\n",
    "data4 = []\n",
    "error = []\n",
    "name_list=[]\n",
    "with open(i, 'r') as fx3:\n",
    "    for line in fx3.readlines():\n",
    "        each_sample_name = np.array(line[0:-1].split(','))[0]\n",
    "        each_sample = np.array(line[0:-1].split(','))[1:].astype('float')\n",
    "        error.append(each_sample)\n",
    "        name_list.append(each_sample_name)\n",
    "error = np.array(error)\n",
    "\n",
    "i = '../../0.prepare_processing/run1/a99.txt'\n",
    "name = i.split('.')[0]\n",
    "sites = []\n",
    "with open(i, 'r') as fx3:\n",
    "    for line in fx3.readlines():\n",
    "        each_sample_name = np.array(line[0:-1].split(','))[0]\n",
    "        each_sample = np.array(line[0:-1].split(','))[1:].astype('int32')\n",
    "        sites.append(each_sample)\n",
    "sites = np.array(sites)\n",
    "\n",
    "f = open(f\"99_result.txt\", \"a+\")\n",
    "print('sample','precise', 'max_cutoff', 'max_num', 'error_rate',sep=',', file=f)\n",
    "for i in range(error.shape[0]):\n",
    "    site_info = sites[i]\n",
    "    error_info = error[i]\n",
    "    site_info[error_info > 0.002] = 0\n",
    "    max_index = np.argmax(site_info)\n",
    "    if error_info[max_index] >= 0.002 or site_info[max_index]==0 :\n",
    "        error_info[error_info == 0] =1\n",
    "        error_rate=error_info[np.argmin(error_info)]\n",
    "    else:\n",
    "        error_rate=error_info[max_index]\n",
    "    print(name_list[i],99, max_index, np.max(site_info), error_rate, sep=',', file=f)\n",
    "f.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precise  max_cutoff  max_num  error_rate\n",
      "sample                                             \n",
      "sample107       99           1      276    0.001893\n",
      "sample105       99           1      430    0.001320\n",
      "sample103       99           1      405    0.001222\n",
      "sample108       99           1      367    0.001091\n",
      "sample106       99           1      490    0.001302\n",
      "...            ...         ...      ...         ...\n",
      "sample91        99           2      388    0.001073\n",
      "sample95        99           2      416    0.000717\n",
      "sample97        99           1      343    0.001601\n",
      "sample98        99           1      506    0.000988\n",
      "sample99        99           2      250    0.000840\n",
      "\n",
      "[192 rows x 4 columns]\n",
      "       precise  max_cutoff     max_num  error_rate\n",
      "count    192.0  192.000000  192.000000  192.000000\n",
      "mean      99.0    2.026042  203.645833    0.002299\n",
      "std        0.0    1.020394  178.631738    0.011899\n",
      "min       99.0    0.000000    0.000000    0.000000\n",
      "25%       99.0    2.000000   52.000000    0.000672\n",
      "50%       99.0    2.000000  149.500000    0.000912\n",
      "75%       99.0    2.000000  334.750000    0.001306\n",
      "max       99.0   10.000000  664.000000    0.150000\n"
     ]
    }
   ],
   "source": [
    "# take a look \n",
    "# to tell you where each output comes from we leave a copy where it generates.\n",
    "# you may see the max error rate exceeds the criterion which means the least error rate after 1-10 cutoff is here\n",
    "# and we will discard this sample before following training.\n",
    "# the cause of the high least error rate may be the contaimination or something else which brings in some errors \n",
    "# can not be erased by UMI or removing low RNCU reads.\n",
    "import pandas as pd \n",
    "df=pd.read_csv('99_result.txt',index_col=0)\n",
    "print(df)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
