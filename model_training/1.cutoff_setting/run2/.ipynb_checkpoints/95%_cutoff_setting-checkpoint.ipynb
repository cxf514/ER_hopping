{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author=cxf\n",
    "# date=2020-8-8\n",
    "\"\"\"\n",
    "    file for setting the optimal cutoff for each sample according to the criterion\n",
    "    1.after filtering error rate less than 0.01 (1/5 of 0.05)\n",
    "    2.after filtering the number of genotyped sites is the largest and record the number\n",
    "    (check among points where the error rate less than 0.01)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "i = '../../0.prepare_processing/run2/error.txt'\n",
    "name = i.split('.')[0]\n",
    "data4 = []\n",
    "error = []\n",
    "name_list=[]\n",
    "with open(i, 'r') as fx3:\n",
    "    for line in fx3.readlines():\n",
    "        each_sample_name = np.array(line[0:-1].split(','))[0]\n",
    "        each_sample = np.array(line[0:-1].split(','))[1:].astype('float')\n",
    "        error.append(each_sample)\n",
    "        name_list.append(each_sample_name)\n",
    "error = np.array(error)\n",
    "\n",
    "i = '../../0.prepare_processing/run2/a95.txt'\n",
    "name = i.split('.')[0]\n",
    "sites = []\n",
    "with open(i, 'r') as fx3:\n",
    "    for line in fx3.readlines():\n",
    "        each_sample_name = np.array(line[0:-1].split(','))[0]\n",
    "        each_sample = np.array(line[0:-1].split(','))[1:].astype('int32')\n",
    "        sites.append(each_sample)\n",
    "sites = np.array(sites)\n",
    "\n",
    "f = open(f\"95_result.txt\", \"a+\")\n",
    "print('sample','precise', 'max_cutoff', 'max_num', 'error_rate',sep=',', file=f)\n",
    "for i in range(error.shape[0]):\n",
    "    site_info = sites[i]\n",
    "    error_info = error[i]\n",
    "    site_info[error_info > 0.01] = 0\n",
    "    max_index = np.argmax(site_info)\n",
    "    if error_info[max_index] >= 0.01 or site_info[max_index]==0 :\n",
    "        error_info[error_info == 0] =1\n",
    "        error_rate=error_info[np.argmin(error_info)]\n",
    "    else:\n",
    "        error_rate=error_info[max_index]\n",
    "    print(name_list[i],95, max_index, np.max(site_info), error_rate, sep=',', file=f)\n",
    "f.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precise  max_cutoff  max_num  error_rate\n",
      "sample                                                \n",
      "sample1180-1       95           1      883    0.004718\n",
      "sample1180-2       95           2      414    0.004335\n",
      "sample1180-3       95           1      744    0.004469\n",
      "sample1182-1       95           1      853    0.002547\n",
      "sample1182-2       95           1      851    0.002941\n",
      "...               ...         ...      ...         ...\n",
      "samplePA           95           1      866    0.002814\n",
      "samplePB           95           1      852    0.001297\n",
      "samplePC           95           1      799    0.003347\n",
      "samplePD           95           1      826    0.001843\n",
      "samplePE           95           1      846    0.001789\n",
      "\n",
      "[111 rows x 4 columns]\n",
      "       precise  max_cutoff      max_num  error_rate\n",
      "count    111.0  111.000000   111.000000  111.000000\n",
      "mean      95.0    1.261261   557.837838    0.003967\n",
      "std        0.0    0.670301   368.985330    0.003085\n",
      "min       95.0    0.000000     0.000000    0.000000\n",
      "25%       95.0    1.000000   118.000000    0.001842\n",
      "50%       95.0    1.000000   681.000000    0.003249\n",
      "75%       95.0    2.000000   882.000000    0.005602\n",
      "max       95.0    5.000000  1056.000000    0.022809\n"
     ]
    }
   ],
   "source": [
    "# take a look \n",
    "# to tell you where each output comes from we leave a copy where it generates.\n",
    "# you may see the max error rate exceeds the criterion which means the least error rate after 1-10 cutoff is here\n",
    "# and we will discard this sample before following training.\n",
    "# the cause of the high least error rate may be the contaimination or something else which brings in some errors \n",
    "# can not be erased by UMI or removing low RNCU reads.\n",
    "import pandas as pd \n",
    "df=pd.read_csv('95_result.txt',index_col=0)\n",
    "print(df)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
